# =============================================================================
# Docker Compose Configuration
# =============================================================================
#
# DOCKER COMPOSE BASICS:
# ----------------------
# Docker Compose lets you define and run multi-container applications.
# Instead of running multiple 'docker run' commands, you define everything
# in one YAML file and run 'docker-compose up'.
#
# KEY CONCEPTS:
# - Service: A container definition (image, ports, volumes, etc.)
# - Network: How containers communicate with each other
# - Volume: Persistent storage that survives container restarts
#
# NETWORKING:
# By default, Compose creates a network and all services can reach each other
# by service name. So 'ml-api' can reach 'prometheus' at 'http://prometheus:9090'
#
# =============================================================================

# -----------------------------------------------------------------------------
# SERVICES
# -----------------------------------------------------------------------------
services:

  # ---------------------------------------------------------------------------
  # ML API - Our FastAPI application
  # ---------------------------------------------------------------------------
  ml-api:
    # Use IMAGE env var if set (for CD from registry), otherwise build locally
    # Usage: IMAGE=localhost:5000/ml-api:latest docker-compose up -d
    image: ${IMAGE:-ml-api:local}

    # Build from local Dockerfile (used when IMAGE not set)
    build:
      context: ./ml_api           # Path to build context
      dockerfile: Dockerfile      # Dockerfile to use

    # Container name (optional, but helpful for logs)
    container_name: ml-api

    # Port mapping: host:container
    # Access the API at http://localhost:8000
    ports:
      - "8000:8000"

    # Environment variables
    environment:
      - PYTHONUNBUFFERED=1        # See Python output immediately

    # Health check (Docker monitors container health)
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s               # Check every 30 seconds
      timeout: 10s                # Timeout after 10 seconds
      retries: 3                  # Mark unhealthy after 3 failures
      start_period: 10s           # Wait 10s before first check

    # Restart policy
    restart: unless-stopped

    # Networks (explicit, though default would work)
    networks:
      - monitoring

  # ---------------------------------------------------------------------------
  # Prometheus - Metrics collection and storage
  # ---------------------------------------------------------------------------
  prometheus:
    # Official Prometheus image
    image: prom/prometheus:v2.48.0

    container_name: prometheus

    # Port mapping
    ports:
      - "9090:9090"

    # Mount our config file into the container
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro  # :ro = read-only
      - prometheus_data:/prometheus  # Named volume for data persistence

    # Command line arguments
    # These configure Prometheus behavior
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'  # Config file location
      - '--storage.tsdb.path=/prometheus'               # Data storage path
      - '--storage.tsdb.retention.time=15d'             # Keep 15 days of data
      - '--web.enable-lifecycle'                        # Allow config reload via API
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'

    # Wait for ml-api to be available
    depends_on:
      ml-api:
        condition: service_healthy

    restart: unless-stopped

    networks:
      - monitoring

  # ---------------------------------------------------------------------------
  # Grafana - Visualization and dashboards
  # ---------------------------------------------------------------------------
  grafana:
    # Official Grafana image
    image: grafana/grafana:10.2.0

    container_name: grafana

    # Port mapping
    # Access Grafana at http://localhost:3000
    ports:
      - "3000:3000"

    # Environment variables for initial setup
    environment:
      # Default admin credentials (change in production!)
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      # Allow embedding in iframes (useful for development)
      - GF_SECURITY_ALLOW_EMBEDDING=true
      # Anonymous access (convenient for development)
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer

    # Mount provisioning files
    volumes:
      # Data persistence
      - grafana_data:/var/lib/grafana
      # Auto-configure data sources
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      # Auto-load dashboards
      - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro

    # Wait for Prometheus
    depends_on:
      - prometheus

    restart: unless-stopped

    networks:
      - monitoring

# -----------------------------------------------------------------------------
# NETWORKS
# -----------------------------------------------------------------------------
# Define custom network for service communication
networks:
  monitoring:
    driver: bridge  # Default Docker network driver

# -----------------------------------------------------------------------------
# VOLUMES
# -----------------------------------------------------------------------------
# Named volumes for data persistence
# Data survives container restarts and recreations
volumes:
  prometheus_data:   # Prometheus time-series data
  grafana_data:      # Grafana dashboards, users, settings

# =============================================================================
# USAGE
# =============================================================================
#
# Start all services:
#   docker-compose up -d
#
# View logs:
#   docker-compose logs -f
#   docker-compose logs -f ml-api
#
# Stop all services:
#   docker-compose down
#
# Stop and remove volumes (clean slate):
#   docker-compose down -v
#
# Rebuild after code changes:
#   docker-compose up -d --build
#
# =============================================================================
